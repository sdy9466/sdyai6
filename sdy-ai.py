import streamlit as st
import base64
from dotenv import load_dotenv
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from streamlit_extras.colored_header import colored_header
from streamlit_extras.add_vertical_space import add_vertical_space
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

from utils import dataframe_agent

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æˆ‘çš„AIåŠ©æ‰‹ - å¤§é»„",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'messages' not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": "ä½ æ˜¯åä¸ºå¤§é»„çš„AIåŠ©æ‰‹ï¼Œå‹å¥½ä¸”ä¹äºåŠ©äººï¼Œèƒ½å›ç­”å„ç±»é—®é¢˜"}]
    st.session_state.memory = ConversationBufferMemory(return_messages=True)
    st.session_state.api_key = ""
    st.session_state.df = None  # å­˜å‚¨ä¸Šä¼ çš„æ•°æ®
    st.session_state.current_mode = "normal"  # æ¨¡å¼ï¼šnormalï¼ˆè‡ªç”±æé—®ï¼‰æˆ–dataï¼ˆæ•°æ®é—®ç­”ï¼‰
    st.session_state.theme = "light"  # é»˜è®¤ä¸»é¢˜
    st.session_state.selected_model = "gpt-4o-mini"  # é»˜è®¤æ¨¡å‹
    # è®¾ç½®é»˜è®¤çš„ç³»ç»Ÿè§’è‰²æè¿°ï¼ˆæ”¯æŒMarkdownï¼‰
    st.session_state.messages = [
        {
            "role": "system",
            "content": """
    ä½ æ˜¯ä¸€ä¸ªå‹å¥½ä¸”ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œèƒ½æä¾›æ¸…æ™°æ˜“æ‡‚çš„å›ç­”

    """
        }
    ]
    st.session_state.force_refresh = False  # å¼ºåˆ¶åˆ·æ–°æ ‡è®°

# å¯ç”¨æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = {
    "gpt-4o-mini": "GPT-4o Mini (å¹³è¡¡)",
    "gpt-4o": "GPT-4o (é«˜çº§)",
    "gpt-3.5-turbo": "GPT-3.5 Turbo (ç»æµ)",
    "gpt-3.5-turbo-16k": "GPT-3.5 Turbo 16k (é•¿æ–‡æœ¬)"
}

# æ¨¡å‹é…ç½®
MODEL_CONFIG = {
    "gpt-4o-mini": {"temperature": 0.7, "max_tokens": 8000},
    "gpt-4o": {"temperature": 0.7, "max_tokens": 12000},
    "gpt-3.5-turbo": {"temperature": 0.7, "max_tokens": 4000},
    "gpt-3.5-turbo-16k": {"temperature": 0.7, "max_tokens": 16000}
}

# å®šä¹‰ä¸»é¢˜é…ç½®ï¼ˆä½¿ç”¨CSSå˜é‡ï¼‰
theme_config = {
    "light": {
        "--primary-bg": "white",
        "--text-color": "#333",
        "--sidebar-bg": "#f5f5f5",
        "--chat-max-width": "80%",
    },
    "dark": {
        "--primary-bg": "#1f1f1f",
        "--text-color": "white",
        "--sidebar-bg": "#2d2d2d",
        "--chat-max-width": "80%",
    },
    "blue": {
        "--primary-bg": "#e3f2fd",
        "--text-color": "#000",
        "--sidebar-bg": "#d0e8fa",
        "--chat-max-width": "80%",
    }
}


# åº”ç”¨å½“å‰ä¸»é¢˜çš„CSS
def apply_theme():
    current_theme = theme_config[st.session_state.theme]
    css = f"""
    <style>
    :root {{
        --primary-bg: {current_theme["--primary-bg"]};
        --text-color: {current_theme["--text-color"]};
        --sidebar-bg: {current_theme["--sidebar-bg"]};
        --chat-max-width: {current_theme["--chat-max-width"]};
    }}

    /* åº”ç”¨å…¨å±€æ ·å¼ */
    .stApp {{
        background-color: var(--primary-bg);
        color: var(--text-color);
    }}

    /* ä¾§è¾¹æ æ ·å¼ */
    .sidebar-content {{
        background-color: var(--sidebar-bg);
    }}

    /* èŠå¤©æ¶ˆæ¯æ ·å¼ */
    .stChatMessage {{
        max-width: var(--chat-max-width);
        margin-left: auto;
        margin-right: auto;
    }}
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)


# # åº”ç”¨ä¸»é¢˜
# st.session_state.theme = 'light'
# apply_theme()


# å›¾è¡¨ç”Ÿæˆå‡½æ•°
def create_chart(input_data, chart_type):
    """ç”Ÿæˆç»Ÿè®¡å›¾è¡¨"""
    df_data = pd.DataFrame(
        data={
            "x": input_data["columns"],
            "y": input_data["data"]
        }
    )
    df_data.set_index("x", inplace=True)
    if chart_type == "bar":
        st.bar_chart(df_data)
    elif chart_type == "line":
        plt.figure(figsize=(10, 6))
        plt.plot(df_data.index, df_data["y"], marker="o", linestyle="--")
        plt.ylim(0, df_data["y"].max() * 1.1)
        plt.title("æ•°æ®å¯è§†åŒ–")
        plt.xlabel("ç±»åˆ«")
        plt.ylabel("æ•°å€¼")
        plt.grid(True, linestyle="--", alpha=0.7)
        st.pyplot(plt.gcf())
        plt.clf()  # æ¸…é™¤å›¾è¡¨


# ä¸»é¢˜å˜æ›´å›è°ƒå‡½æ•°
def update_theme(selected_theme):
    st.session_state.theme = selected_theme
    apply_theme()


# æ¨¡å‹å˜æ›´å›è°ƒå‡½æ•°
def update_model():
    # è·å–é€‰æ‹©æ¡†å½“å‰å€¼
    new_model = st.session_state.model_selector
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦çœŸçš„æ”¹å˜
    if new_model != st.session_state.selected_model:
        st.session_state.selected_model = new_model
        st.session_state.force_refresh = True  # æ ‡è®°éœ€è¦åˆ·æ–°

        # é‡ç½®å¯¹è¯é“¾ï¼Œä½¿ç”¨æ–°æ¨¡å‹
        if 'conversation_chain' in st.session_state:
            del st.session_state['conversation_chain']

        # æ˜¾ç¤ºé€šçŸ¥
        st.info(f"å·²åˆ‡æ¢åˆ°æ¨¡å‹: {AVAILABLE_MODELS[new_model]}")


# ä¾§è¾¹æ è®¾è®¡
with st.sidebar:
    # å°†æœ¬åœ°å›¾ç‰‡è½¬æ¢ä¸º Base64
    def get_image_base64(path):
        try:
            with open(path, "rb") as img_file:
                return base64.b64encode(img_file.read()).decode()
        except Exception as e:
            st.error(f"æ— æ³•åŠ è½½èƒŒæ™¯å›¾ç‰‡: {str(e)}")
            return None


    # è·å–ç§‘å¹».jpgçš„Base64ç¼–ç 
    image_base64 = get_image_base64("ç§‘å¹»1.png")


    if image_base64:
        # æ·»åŠ ä¾§è¾¹æ èƒŒæ™¯å›¾ç‰‡
        st.markdown(
            f"""
                <style>
                [data-testid="stSidebar"] {{
                    background-image: url("data:image/jpg;base64,{image_base64}");
                    background-size: cover;
                    background-position: center;
                    background-repeat: no-repeat;
                    /* æ·»åŠ åŠé€æ˜é®ç½©å±‚ï¼Œç¡®ä¿æ–‡å­—å¯è¯»æ€§ */
                    background-blend-mode: overlay;
                    background-color: rgba(255, 255, 255, 0.5);  /* ç™½è‰²é®ç½©ï¼Œé€æ˜åº¦70% */
                }}

                /* è°ƒæ•´ä¾§è¾¹æ æ–‡å­—é¢œè‰²ï¼Œç¡®ä¿åœ¨èƒŒæ™¯ä¸Šæ¸…æ™°å¯è§ */
                [data-testid="stSidebar"] .sidebar-content {{
                    color: #333;  /* æ·±ç°è‰²æ–‡å­— */
                }}

                /* è°ƒæ•´æŒ‰é’®å’Œè¾“å…¥æ¡†æ ·å¼ */
                [data-testid="stSidebar"] button,
                [data-testid="stSidebar"] input {{
                    background-color: rgba(255, 255, 255, 0.8);  /* åŠé€æ˜ç™½è‰² */
                    border-radius: 4px;
                }}
                </style>
                """,
            unsafe_allow_html=True
        )

    st.image("./jiqi.png", caption="å¤§é»„", use_container_width=True)
    st.title("âœ¨ ç³»ç»Ÿè®¾ç½®")

    # APIå¯†é’¥è¾“å…¥
    st.subheader("ğŸ”‘ APIå¯†é’¥ç®¡ç†")
    api_key = st.text_input(
        "è¯·è¾“å…¥OpenAI APIå¯†é’¥ï¼š",
        type="password",
        placeholder="hk-xxxxxxxxxxxxxxxxxxxx",
        # value=st.session_state.api_key
    )
    if api_key:
        st.session_state.api_key = api_key

    # ç³»ç»Ÿè§’è‰²è®¾ç½®
    st.subheader("ğŸ­ è§’è‰²è®¾å®š")
    system_role = st.text_area(
        "è®¾ç½®AIè§’è‰²ï¼ˆæ”¯æŒMarkdownï¼‰ï¼š",
        value=st.session_state.messages[0]["content"],  # ä½¿ç”¨å½“å‰ç³»ç»Ÿæ¶ˆæ¯ä½œä¸ºé»˜è®¤å€¼
        height=150,
        key="sidebar_system_role_text_area"
    )
    if st.button("æ›´æ–°è§’è‰²è®¾å®š", key="update_role_button"):
        st.session_state.messages[0]["content"] = system_role

        # é‡ç½®å¯¹è¯é“¾ï¼Œå¼ºåˆ¶ä½¿ç”¨æ–°çš„ç³»ç»Ÿæ¶ˆæ¯
        if 'conversation_chain' in st.session_state:
            del st.session_state['conversation_chain']

        st.success("âœ… è§’è‰²è®¾å®šå·²æ›´æ–°ï¼")  # æ˜¾ç¤ºæˆåŠŸæç¤º

    # æ¨¡å‹é€‰æ‹©
    st.subheader("ğŸ¤– æ¨¡å‹é€‰æ‹©")
    st.selectbox(
        "é€‰æ‹©AIæ¨¡å‹ï¼š",
        list(AVAILABLE_MODELS.keys()),
        format_func=lambda x: AVAILABLE_MODELS[x],
        index=list(AVAILABLE_MODELS.keys()).index(st.session_state.selected_model),
        on_change=update_model,
        key="model_selector"
    )

    # æ˜¾ç¤ºå½“å‰æ¨¡å‹ä¿¡æ¯
    st.write(f"å½“å‰ä½¿ç”¨: {AVAILABLE_MODELS[st.session_state.selected_model]}")
    st.write(f"ä¸Šä¸‹æ–‡é•¿åº¦: {MODEL_CONFIG[st.session_state.selected_model]['max_tokens']} tokens")

    # æ¨¡å¼åˆ‡æ¢
    st.subheader("ğŸ”„ æ¨¡å¼åˆ‡æ¢")
    mode = st.radio("é€‰æ‹©æ¨¡å¼ï¼š", ["è‡ªç”±æé—®", "æ•°æ®é—®ç­”"],
                    index=0 if st.session_state.current_mode == "normal" else 1)
    if mode == "è‡ªç”±æé—®" and st.session_state.current_mode != "normal":
        st.session_state.current_mode = "normal"
    elif mode == "æ•°æ®é—®ç­”" and st.session_state.current_mode != "data":
        st.session_state.current_mode = "data"

    # æ•°æ®ä¸Šä¼ åŠŸèƒ½ï¼ˆä»…åœ¨æ•°æ®é—®ç­”æ¨¡å¼æ˜¾ç¤ºï¼‰
    if st.session_state.current_mode == "data":
        st.subheader("ğŸ“Š æ•°æ®ä¸Šä¼ ")
        option = st.radio("è¯·é€‰æ‹©æ•°æ®æ–‡ä»¶ç±»å‹:", ("Excel", "CSV"))
        file_type = "xlsx" if option == "Excel" else "csv"
        data = st.file_uploader(f"ä¸Šä¼ ä½ çš„{option}æ•°æ®æ–‡ä»¶", type=file_type)
        if data:
            try:
                if file_type == "xlsx":
                    st.session_state["df"] = pd.read_excel(data, sheet_name='data')
                else:
                    st.session_state["df"] = pd.read_csv(data)
                with st.expander("åŸå§‹æ•°æ®"):
                    st.dataframe(st.session_state["df"])
            except Exception as e:
                st.error(f"æ— æ³•è¯»å–æ–‡ä»¶: {str(e)}")


    # ä¾§è¾¹æ ä¸»é¢˜åˆ‡æ¢éƒ¨åˆ†
    st.subheader("ğŸ¨ ç•Œé¢ä¸»é¢˜")
    new_theme = st.radio(
        "é€‰æ‹©ä¸»é¢˜ï¼š",
        ["light", "dark", "blue"],
        index=1
        # key="theme_selector"
    )

    # åœ¨ä¸»å¾ªç¯ä¸­æ£€æŸ¥å˜åŒ–
    # if 'theme_selector' in st.session_state and st.session_state.theme_selector != st.session_state.theme:
    #     st.session_state.theme = st.session_state.theme_selector
    #     apply_theme()

    if 'theme' in st.session_state and new_theme != st.session_state.theme:
        st.session_state.theme = new_theme
        apply_theme()

    # åŠŸèƒ½æŒ‰é’®
    add_vertical_space(2)
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²", key="clear_conversation_button"):
        st.session_state.messages = [st.session_state.messages[0]]
        st.session_state.memory.clear()
    if st.button("ğŸš€ é‡æ–°åˆå§‹åŒ–", key="reinitialize_button"):
        st.session_state.clear()
        # é‡ç½®ä¸»é¢˜å’Œæ¨¡å‹çŠ¶æ€
        st.session_state.theme = "light"
        st.session_state.selected_model = "gpt-4o-mini"
        st.session_state.force_refresh = False
        apply_theme()


# å¼ºåˆ¶åˆ·æ–°é€»è¾‘ - ä½¿ç”¨éšè—æŒ‰é’®
if st.session_state.force_refresh:
    # åˆ›å»ºä¸€ä¸ªéšè—çš„æŒ‰é’®å¹¶ç«‹å³ç‚¹å‡»å®ƒæ¥è§¦å‘åˆ·æ–°
    st.session_state.force_refresh = False
    col1, col2 = st.columns([9, 1])
    with col2:
        if st.button("åˆ·æ–°", key="hidden_refresh_button"):
            pass

# ä¸»ç•Œé¢å¸ƒå±€
st.title("ğŸ¤– æˆ‘çš„AIåŠ©æ‰‹ - å¤§é»„")
if st.session_state.current_mode == "normal":
    colored_header(label="", description="è‡ªç”±æé—®æ¨¡å¼ï¼šç›´æ¥è¾“å…¥ä»»ä½•é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›è§£ç­”ï¼", color_name="blue-70")
else:
    colored_header(label="", description="æ•°æ®é—®ç­”æ¨¡å¼ï¼šä¸Šä¼ æ•°æ®åï¼Œå¯è¯¢é—®ä¸æ•°æ®ç›¸å…³çš„é—®é¢˜", color_name="blue-70")

# æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„æ¨¡å‹
st.write(f"ğŸ’¡ å½“å‰ä½¿ç”¨æ¨¡å‹: **{AVAILABLE_MODELS[st.session_state.selected_model]}**")

# æ˜¾ç¤ºæ•°æ®ä¸Šä¼ çŠ¶æ€ï¼ˆä»…åœ¨æ•°æ®é—®ç­”æ¨¡å¼æ˜¾ç¤ºï¼‰
if st.session_state.current_mode == "data" and st.session_state.df is not None:
    st.info(f"å½“å‰å·²åŠ è½½æ•°æ®ï¼š{st.session_state.df.shape[0]}è¡Œï¼Œ{st.session_state.df.shape[1]}åˆ—")

# æ˜¾ç¤ºå¯¹è¯å†å²
for msg in st.session_state.messages:
    if msg["role"] == "system":
        continue  # ä¸æ˜¾ç¤ºç³»ç»Ÿè§’è‰²
    st.chat_message(msg["role"]).write(msg["content"])

# æ ¹æ®æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„è¾“å…¥ç•Œé¢
if st.session_state.current_mode == "normal":
    # è‡ªç”±æé—®æ¨¡å¼è¾“å…¥æ¡†
    user_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜ï¼ˆæ”¯æŒMarkdownæ ¼å¼ï¼‰ï¼š")

    if user_input:
        # æ£€æŸ¥APIå¯†é’¥
        if not st.session_state.api_key:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥APIå¯†é’¥", icon="âš ï¸")
            st.stop()

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.chat_message("human").write(user_input)
        st.session_state.messages.append({"role": "human", "content": user_input})

        # åœ¨è‡ªç”±æé—®æ¨¡å¼ç”ŸæˆAIå›å¤çš„éƒ¨åˆ†
        with st.spinner("å¤§é»„çƒ§è„‘ä¸­..."):
            placeholder = st.empty()  # åˆ›å»ºå ä½ç¬¦ç”¨äºæ˜¾ç¤º GIF
            try:
                # è·å–å½“å‰æ¨¡å‹é…ç½®
                model_config = MODEL_CONFIG[st.session_state.selected_model]

                # åˆ›å»ºæˆ–è·å–å¯¹è¯é“¾
                if 'conversation_chain' not in st.session_state:
                    model = ChatOpenAI(
                        model=st.session_state.selected_model,
                        api_key=st.session_state.api_key,
                        base_url="https://twapi.openai-hk.com/v1",
                        temperature=model_config["temperature"],
                        max_tokens=model_config["max_tokens"]
                    )

                    # ä½¿ç”¨ ChatPromptTemplate æ˜ç¡®è®¾ç½®ç³»ç»Ÿæ¶ˆæ¯
                    from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

                    prompt_template = ChatPromptTemplate.from_messages([
                        ("system", st.session_state.messages[0]["content"]),
                        MessagesPlaceholder(variable_name="history"),
                        ("human", "{input}")
                    ])

                    st.session_state.conversation_chain = ConversationChain(
                        llm=model,
                        prompt=prompt_template,
                        memory=st.session_state.memory,
                        verbose=True
                    )

                # æ˜¾ç¤º GIF åŠ¨å›¾
                gif_url = "å®•æœº.jpg"
                placeholder.image(gif_url, width=80)

                # ä½¿ç”¨å¯¹è¯é“¾ç”Ÿæˆå›å¤
                response = st.session_state.conversation_chain.predict(input=user_input)

                # æ˜¾ç¤ºAIå›å¤
                st.chat_message("ai").write(response)
                st.session_state.messages.append({"role": "ai", "content": response})

            except Exception as e:
                st.error(f"ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {str(e)}")
            finally:
                placeholder.empty()
else:
    # æ•°æ®é—®ç­”æ¨¡å¼è¾“å…¥æ¡†
    query = st.text_area(
        "è¯·è¾“å…¥ä½ å…³äºä»¥ä¸Šæ•°æ®é›†çš„é—®é¢˜æˆ–æ•°æ®å¯è§†åŒ–éœ€æ±‚ï¼š",
        disabled="df" not in st.session_state or st.session_state.df is None,
        key="main_query_text_area"
    )
    button = st.button("ç”Ÿæˆå›ç­”", key="main_generate_answer_button")

    if button and ("df" not in st.session_state or st.session_state.df is None):
        st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        st.stop()

    if button and query:
        with st.spinner("å¤§é»„çƒ§è„‘ä¸­..."):
            placeholder = st.empty()  # åˆ›å»ºå ä½ç¬¦ç”¨äºæ˜¾ç¤º GIF
            try:

                # æ˜¾ç¤º GIF åŠ¨å›¾ï¼ˆç¤ºä¾‹åœ°å€ï¼Œå¯æ›¿æ¢ä¸ºæœ¬åœ°æ–‡ä»¶æˆ–è‡ªå®šä¹‰ URLï¼‰
                gif_url = "å®•æœº.jpg"  # ç¤ºä¾‹ï¼šæ€è€ƒä¸­çš„æœºå™¨äºº
                placeholder.image(gif_url, width=80)  # è°ƒæ•´å®½åº¦
                result = dataframe_agent(st.session_state["df"], query)

                if "answer" in result:
                    st.chat_message("ai").write(result["answer"])
                    st.session_state.messages.append({"role": "ai", "content": result["answer"]})
                if "table" in result:
                    st.chat_message("ai").table(pd.DataFrame(result["table"]["data"],
                                                             columns=result["table"]["columns"]))

                if "bar" in result:
                    st.chat_message("ai").markdown("### æŸ±çŠ¶å›¾åˆ†æ")
                    create_chart(result["bar"], "bar")
                if "line" in result:
                    st.chat_message("ai").markdown("### æŠ˜çº¿å›¾åˆ†æ")
                    create_chart(result["line"], "line")


            except Exception as e:
                st.error(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
            finally:
                placeholder.empty()  #

# åº•éƒ¨æç¤º
st.markdown("""
    <div style="text-align: right; color: #666; margin-top: 2rem;">
        æç¤ºï¼šè¾“å…¥ <code>/help</code> æŸ¥çœ‹åŠŸèƒ½åˆ—è¡¨ | ä½¿ç”¨ä¾§è¾¹æ åˆ‡æ¢æ¨¡å¼
    </div>
    """, unsafe_allow_html=True)